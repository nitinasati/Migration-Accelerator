# Migration-Accelerators Environment Configuration

# LLM Provider Configuration
LLM_PROVIDER=openai  # openai, bedrock, anthropic, vertexai
LLM_MODEL=gpt-4
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=4000

# API Keys
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
AWS_ACCESS_KEY_ID=your_aws_access_key_here
AWS_SECRET_ACCESS_KEY=your_aws_secret_key_here
AWS_REGION=us-east-1

# LangSmith Configuration
LANGSMITH_API_KEY=your_langsmith_api_key_here
LANGSMITH_PROJECT=migration-accelerators
LANGSMITH_TRACING_V2=true

# MCP Configuration
MCP_SERVER_URL=http://localhost:3000
MCP_API_KEY=your_mcp_api_key_here
MCP_TIMEOUT=30
MCP_MAX_RETRIES=3

# File Processing
MAX_FILE_SIZE_MB=100
CHUNK_SIZE=1000
TEMP_DIRECTORY=./temp

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json
